{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bfc754a9063321",
   "metadata": {},
   "source": [
    "## Summary assignment - part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9cc2d12b60273",
   "metadata": {},
   "source": [
    "### Odeya Hazani- 207288457\n",
    "### Roni Epstein- 211645825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09af80dc-93d2-471d-8e0e-c3004e3ee304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:48.733137Z",
     "start_time": "2024-06-02T09:41:48.257446Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b54b18a-0551-4c31-ab9b-4750820ae1c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:48.739182Z",
     "start_time": "2024-06-02T09:41:48.734142Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate the number of days until the start of a given month and year\n",
    "def days_until_month_start(year, month):\n",
    "    today = datetime.today()\n",
    "    first_day_of_month = datetime(year, month, 1)\n",
    "    difference = first_day_of_month - today\n",
    "    return difference.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dab609-944a-497c-aeb0-e6e702c28d8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:48.747608Z",
     "start_time": "2024-06-02T09:41:48.739693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the URL of the website and the car model to search for\n",
    "car_model =\"שברולט\"\n",
    "url = \"https://www.ad.co.il/car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8767fd3a-23a6-4d86-9a52-d6266f5d9652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:49.321470Z",
     "start_time": "2024-06-02T09:41:48.748608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Send a request to the website and parse the content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31bc283bba2acb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the section containing the car model\n",
    "car_shev = soup.find_all(\"div\", class_=\"fast-filters-children d-flex flex-row align-items-center me-3 mb-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37721ab3-0a6e-408b-b30a-52e7eaa15f91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:49.330446Z",
     "start_time": "2024-06-02T09:41:49.323474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?sp261=13891'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the URL for the specific car model\n",
    "for element in car_shev:\n",
    "    anchor_tags = element.find_all(\"a\")  # Find all anchor tags within this element\n",
    "    for tag in anchor_tags:\n",
    "        if car_model in tag.text:\n",
    "            tag_model = tag['href']\n",
    "            keywords_model = tag_model[tag_model.find(\"?\"):]\n",
    "            \n",
    "keywords_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7cd64-6e37-4964-beb8-8b5a0e318866",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38493be25be92b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a request to the car model's URL and parse the content\n",
    "response = requests.get(url+keywords_model)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb685d1-d9dd-40a4-b235-b7db015d149e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:49.848088Z",
     "start_time": "2024-06-02T09:41:49.331447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/car?sp261=13891&pageindex=4',\n",
       " '/car?sp261=13891',\n",
       " '/car?sp261=13891&pageindex=2',\n",
       " '/car?sp261=13891&pageindex=3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract pagination URLs\n",
    "pagination = soup.find('ul', class_=\"pagination justify-content-between justify-content-sm-center flex-wrap\")\n",
    "page_items = pagination.find_all('li', class_=\"page-item\")\n",
    "page_urls_all = [item.find('a')['href'] for item in page_items if item.find('a')]\n",
    "page_urls = list(set(page_urls_all))\n",
    "page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "541568d8-d2c6-4f75-b00e-834400347ba7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:52.152652Z",
     "start_time": "2024-06-02T09:41:49.848088Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to scrape data IDs from each page\n",
    "def scrape_data_ids(url_model):\n",
    "    url = \"https://www.ad.co.il\"\n",
    "    response = requests.get(url_model)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    cards_container = soup.find('div', class_='cards-wrap s m l')\n",
    "    data_ids = []\n",
    "    cards = cards_container.find_all('div', class_='card-block')\n",
    "    for card in cards:\n",
    "        data_id = card.get('data-id')\n",
    "        if data_id:  # Check if data-id is not None\n",
    "            data_id = url + \"/ad/\" + str(data_id)\n",
    "            data_ids.append(data_id)\n",
    "    return data_ids\n",
    "\n",
    "data_ids_pags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545946276e539c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data IDs collected: 183\n"
     ]
    }
   ],
   "source": [
    "# Collect data IDs from all pages\n",
    "for page_url in page_urls:\n",
    "    full_url = 'https://www.ad.co.il' + page_url\n",
    "    data_ids = scrape_data_ids(full_url)\n",
    "    data_ids_pags.extend(data_ids)\n",
    "\n",
    "print(f\"Total data IDs collected: {len(data_ids_pags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c003ea6-50ae-4500-9c5a-363a0b0efd26",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97eda63f-f37b-450c-9a6e-f30118d15668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:52.163484Z",
     "start_time": "2024-06-02T09:41:52.153478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to scrape car data from each car's page\n",
    "def scrape_car_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    manufactor = car_model\n",
    "    cars_card_div = soup.find('div', class_=\"d-flex justify-content-between\") \n",
    "    cars_card = cars_card_div.find_all('h2', class_=\"card-title\")\n",
    "    if len(cars_card) == 1:\n",
    "        price = None\n",
    "    else:\n",
    "        price = float(cars_card[1].get_text()[:-1].replace(',', '').replace('₪', '').strip()) if cars_card else None\n",
    "    \n",
    "    model_string = cars_card[0].get_text().split() if cars_card else 'N/A'  \n",
    "    model = ' '.join(model_string[1:])\n",
    "\n",
    "    cars_table = soup.find('table', class_=\"table table-sm mb-4\")\n",
    "    rows = cars_table.find_all('tr') if cars_table else []\n",
    "       \n",
    "    # Initialize variables \n",
    "    year = None\n",
    "    hand = None\n",
    "    gear = 'N/A'\n",
    "    engine_capacity = None\n",
    "    engine_type = 'N/A'\n",
    "    area = 'N/A'\n",
    "    city = 'N/A'     \n",
    "    prev_ownership =  'N/A'\n",
    "    curr_ownership = 'N/A'\n",
    "    color = 'N/A'\n",
    "    test_date = None\n",
    "    km = None\n",
    "        \n",
    "    # Extract data from the table\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) == 2:\n",
    "            key = cells[0].text.strip()\n",
    "            value = cells[1].text.strip()\n",
    "\n",
    "            if key == 'שנה':\n",
    "                year = int(value)\n",
    "            elif key == 'יד':\n",
    "                hand = int(value)   \n",
    "            elif key == 'ת. הילוכים':\n",
    "                gear = value\n",
    "            elif key == 'נפח':\n",
    "                engine_capacity = int(value.replace(',', ''))  # Remove comma from engine capacity\n",
    "            elif key == 'סוג מנוע':\n",
    "                engine_type = value\n",
    "            elif key == 'אזור':\n",
    "                area = value\n",
    "            elif key == 'עיר':\n",
    "                city = value\n",
    "            elif key == 'ק\"מ':\n",
    "                km = int(value.replace(',', ''))\n",
    "            elif key == 'צבע':\n",
    "                color = value\n",
    "            elif key == 'בעלות קודמת':\n",
    "                prev_ownership = value\n",
    "            elif key == 'בעלות נוכחית':\n",
    "                curr_ownership = value\n",
    "            elif key == 'טסט עד':\n",
    "                test_date = value\n",
    "    \n",
    "    test = days_until_month_start(int(test_date.split(\"/\")[1]),int(test_date.split(\"/\")[0])) if test_date else None\n",
    "    cre_date =soup.find_all('div',class_=\"px-3\")[0].get_text().split()[-1] if soup.find_all('div',class_=\"px-3\")[0] else 'N/A'\n",
    "    repub_date = soup.find_all('div',class_=\"px-3\")[1].get_text().split()[-1] if soup.find_all('div',class_=\"px-3\")[0] else 'N/A'\n",
    "    description = soup.find('p',class_=\"text-word-break\").get_text().replace('\\n', '').replace('\\r', ' ') if soup.find('p',class_=\"text-word-break\") else 'No description'\n",
    "    pic_num = len(soup.find_all('div', class_='justify-content-center px-1')) if soup.find_all('div', class_='justify-content-center px-1') else None\n",
    "    supply_score = None\n",
    "\n",
    "    # Add each car's data as a list to the car_data list\n",
    "    car_data =[manufactor, year, model, hand, gear, engine_capacity, engine_type, prev_ownership,\n",
    "                      curr_ownership, area, city, price, pic_num, cre_date, repub_date, description, color, km,test, supply_score]\n",
    "    return car_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2ea42b-ff4c-43c6-ba15-67ce530251aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:41:52.172813Z",
     "start_time": "2024-06-02T09:41:52.164471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the specified columns\n",
    "df = pd.DataFrame(columns=['manufactor','Year','model','Hand','Gear','capacity_Engine','Engine_type','Prev_ownership',\n",
    "                                         'Curr_ownership','Area','City','Price','Pic_num','Cre_date','Repub_date','Description','Color','Km',\n",
    "                                         'Test','Supply_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c847e7e-94a4-4e17-9b4b-983abb825cfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:43:54.305292Z",
     "start_time": "2024-06-02T09:41:52.173813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scrape car data for each car and add to the DataFrame\n",
    "list_cars = []\n",
    "for car_url in data_ids_pags:\n",
    "    car_data = scrape_car_data(car_url)\n",
    "    df.loc[len(df)]=car_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a57659-84b4-4d0c-9e04-8ed99145f4c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T10:19:53.286179Z",
     "start_time": "2024-06-02T10:19:53.274021Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Repub_date'] = pd.to_datetime(df['Repub_date'], format='%d/%m/%Y')\n",
    "df['Cre_date'] = pd.to_datetime(df['Cre_date'], format='%d/%m/%Y')\n",
    "\n",
    "df['Pic_num'] = df['Pic_num'].fillna(0).astype(int)\n",
    "df['Price'] = df['Price'].astype(float)\n",
    "#df['Km'] = df['Km'].astype(int)\n",
    "#df['Test'] = df['Test'].astype(int)\n",
    "\n",
    "df['Gear'] = df['Gear'].astype('category')\n",
    "df['Engine_type'] = df['Engine_type'].astype('category')\n",
    "df['Prev_ownership'] = df['Prev_ownership'].astype('category')\n",
    "df['Curr_ownership'] = df['Curr_ownership'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9410ddd-44ec-4b24-9b06-c36ff1b59f14",
   "metadata": {},
   "source": [
    "________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f2355-b929-4500-8901-f7b405f43356",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Supply_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ee894a4363322e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:43:54.326328Z",
     "start_time": "2024-06-02T09:43:54.321518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ספארק', 'אבאו', 'אורלנדו', 'סוניק', 'מאליבו', 'אקווינוקס',\n",
       "       'אוואו', 'טראקס', 'קרוז', 'קאמרו', 'סלבריטי', 'קורבט', 'אימפלה',\n",
       "       'אופטרה', 'קורבט Z06', 'קורסיקה', 'אפיקה', 'קוואליר', 'אפלנדר',\n",
       "       'קרוז החדשה', 'קאמארו', 'אלרו'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96cce6067010c1df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:43:54.331693Z",
     "start_time": "2024-06-02T09:43:54.326328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary to map Hebrew model names to English model names\n",
    "hebrew_to_english = {\n",
    "    'קרוז': 'Cruz',\n",
    "    'אורלנדו': 'Orlando',\n",
    "    'מליבו': 'Malibu',\n",
    "    'ספארק': 'Spark',\n",
    "    'אקווינוקס': 'Equinox',\n",
    "    'סוניק': 'Sonic',\n",
    "    'קורבט': 'Corvette',\n",
    "    'אבאו': 'Avo',\n",
    "    'אימפלה': 'Impala',\n",
    "    'אופטרה': 'Optera',\n",
    "    'קורבט Z06': 'Corvette Z06',\n",
    "    'אוואו': 'Aww',\n",
    "    'קורסיקה': 'Corsica',\n",
    "    'קאמרו': 'Camaro',\n",
    "    'טראקס': 'Trax',\n",
    "    'אפיקה': 'Epica',\n",
    "    'קוואליר': 'Cavalier',\n",
    "    'אפלנדר': 'Uplander',\n",
    "    'קרוז החדשה': 'New Cruz',\n",
    "    'קאמארו': 'Camaro',\n",
    "    'סלבריטי': 'Celebrity',\n",
    "    'אלרו': 'Alero'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91f217f63f2fd48b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:43:54.336995Z",
     "start_time": "2024-06-02T09:43:54.332792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert Hebrew model names to English\n",
    "def convert_model_name(model_name):\n",
    "    return hebrew_to_english.get(model_name, model_name)  # Return the English name if found, otherwise return the original name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713232107b657ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:43:54.342160Z",
     "start_time": "2024-06-02T09:43:54.337485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the conversion function and create a new column\n",
    "df['english-model'] = df['model'].apply(convert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f13a95c7-c146-4b9c-9fd0-7650053bd5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:43:55.383586Z",
     "start_time": "2024-06-02T09:43:54.348678Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert the data to a DataFrame\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m api_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'result'"
     ]
    }
   ],
   "source": [
    "# URL to the API\n",
    "api_url = 'https://data.gov.il/api/3/action/datastore_search?resource_id=5e87a7a1-2f6f-41c1-8aec-7216d52a6cf6'\n",
    "\n",
    "# Fetch data from the API\n",
    "response = requests.get(api_url)\n",
    "data = response.json()\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "api_df = pd.DataFrame(data['result']['records'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7dbaf3e9964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrame with the API data on the relevant columns\n",
    "merged_df = pd.merge(df, api_df, left_on=['manufactor', 'english-model', 'Year'],\n",
    "                     right_on=['tozar', 'kinuy_mishari', 'shnat_yitzur'], how='left')\n",
    "\n",
    "# Calculate the supply index by counting the number of matches\n",
    "supply_index = merged_df.groupby(['manufactor', 'english-model', 'Year']).size().reset_index(name='supply_index')\n",
    "\n",
    "# Merge the supply index back into the original DataFrame\n",
    "df = pd.merge(df, supply_index, on=['manufactor', 'english-model', 'Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cb99255d8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the temporary 'english-model' column\n",
    "df.drop('english-model', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371bbf4948a0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
